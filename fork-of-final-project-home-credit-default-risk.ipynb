{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af04418",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:09.826452Z",
     "iopub.status.busy": "2022-06-12T12:20:09.826130Z",
     "iopub.status.idle": "2022-06-12T12:20:09.837464Z",
     "shell.execute_reply": "2022-06-12T12:20:09.836821Z"
    },
    "papermill": {
     "duration": 0.027526,
     "end_time": "2022-06-12T12:20:09.840393",
     "exception": false,
     "start_time": "2022-06-12T12:20:09.812867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/home-credit-default-risk/sample_submission.csv\n",
      "/kaggle/input/home-credit-default-risk/bureau_balance.csv\n",
      "/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv\n",
      "/kaggle/input/home-credit-default-risk/application_train.csv\n",
      "/kaggle/input/home-credit-default-risk/HomeCredit_columns_description.csv\n",
      "/kaggle/input/home-credit-default-risk/application_test.csv\n",
      "/kaggle/input/home-credit-default-risk/previous_application.csv\n",
      "/kaggle/input/home-credit-default-risk/credit_card_balance.csv\n",
      "/kaggle/input/home-credit-default-risk/installments_payments.csv\n",
      "/kaggle/input/home-credit-default-risk/bureau.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9547b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:09.865855Z",
     "iopub.status.busy": "2022-06-12T12:20:09.865247Z",
     "iopub.status.idle": "2022-06-12T12:20:12.089946Z",
     "shell.execute_reply": "2022-06-12T12:20:12.089071Z"
    },
    "papermill": {
     "duration": 2.239001,
     "end_time": "2022-06-12T12:20:12.092153",
     "exception": false,
     "start_time": "2022-06-12T12:20:09.853152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "file_name = '/kaggle/working/data.pickl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466f1649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:12.116718Z",
     "iopub.status.busy": "2022-06-12T12:20:12.116470Z",
     "iopub.status.idle": "2022-06-12T12:20:12.122520Z",
     "shell.execute_reply": "2022-06-12T12:20:12.121717Z"
    },
    "papermill": {
     "duration": 0.020184,
     "end_time": "2022-06-12T12:20:12.124354",
     "exception": false,
     "start_time": "2022-06-12T12:20:12.104170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0206cf65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:12.149617Z",
     "iopub.status.busy": "2022-06-12T12:20:12.149354Z",
     "iopub.status.idle": "2022-06-12T12:20:12.167945Z",
     "shell.execute_reply": "2022-06-12T12:20:12.166872Z"
    },
    "papermill": {
     "duration": 0.033756,
     "end_time": "2022-06-12T12:20:12.169882",
     "exception": false,
     "start_time": "2022-06-12T12:20:12.136126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = True):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau_balance.csv', nrows = num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272251d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:12.194194Z",
     "iopub.status.busy": "2022-06-12T12:20:12.193922Z",
     "iopub.status.idle": "2022-06-12T12:20:12.218912Z",
     "shell.execute_reply": "2022-06-12T12:20:12.217956Z"
    },
    "papermill": {
     "duration": 0.040023,
     "end_time": "2022-06-12T12:20:12.221201",
     "exception": false,
     "start_time": "2022-06-12T12:20:12.181178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('/kaggle/input/home-credit-default-risk/previous_application.csv', nrows = num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n",
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = pd.read_csv('/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv', nrows = num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg\n",
    "    \n",
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('/kaggle/input/home-credit-default-risk/installments_payments.csv', nrows = num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = pd.read_csv('/kaggle/input/home-credit-default-risk/credit_card_balance.csv', nrows = num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a83e54",
   "metadata": {
    "papermill": {
     "duration": 0.0107,
     "end_time": "2022-06-12T12:20:12.243007",
     "exception": false,
     "start_time": "2022-06-12T12:20:12.232307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb\n",
    "https://stackoverflow.com/questions/70841834/false-positive-vs-false-negative-trade-off-plot\n",
    "https://towardsdatascience.com/how-to-deal-with-imbalanced-classification-without-re-balancing-the-data-8a3c02353fe3\n",
    "https://towardsdatascience.com/classifying-model-outcomes-true-false-positives-negatives-177c1e702810\n",
    "https://www.analyticsvidhya.com/blog/2020/11/a-tour-of-evaluation-metrics-for-machine-learning/\n",
    "https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0e5a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:12.266834Z",
     "iopub.status.busy": "2022-06-12T12:20:12.266278Z",
     "iopub.status.idle": "2022-06-12T12:20:12.615337Z",
     "shell.execute_reply": "2022-06-12T12:20:12.614621Z"
    },
    "papermill": {
     "duration": 0.363719,
     "end_time": "2022-06-12T12:20:12.617648",
     "exception": false,
     "start_time": "2022-06-12T12:20:12.253929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  \"Since version 1.0, \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import model_selection, metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9763b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:12.644417Z",
     "iopub.status.busy": "2022-06-12T12:20:12.644060Z",
     "iopub.status.idle": "2022-06-12T12:20:12.651455Z",
     "shell.execute_reply": "2022-06-12T12:20:12.650399Z"
    },
    "papermill": {
     "duration": 0.021798,
     "end_time": "2022-06-12T12:20:12.653342",
     "exception": false,
     "start_time": "2022-06-12T12:20:12.631544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def getDatasets(df):\n",
    "    print(\"### Total datapoints {} ###\".format(df))\n",
    "    df = df[df['TARGET'].notnull()]\n",
    "    print(\"### Datapoints excluding test file {} ###\".format(df))\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    feature_col_names = [f for f in df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    predicted_class_names = ['TARGET']\n",
    "    \n",
    "    X = df[feature_col_names].values\n",
    "\n",
    "    Y = df[predicted_class_names].values\n",
    "\n",
    "    split_test_size = 0.3\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=split_test_size, random_state = 42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e8327f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:12.677923Z",
     "iopub.status.busy": "2022-06-12T12:20:12.677414Z",
     "iopub.status.idle": "2022-06-12T12:20:12.687329Z",
     "shell.execute_reply": "2022-06-12T12:20:12.686428Z"
    },
    "papermill": {
     "duration": 0.024621,
     "end_time": "2022-06-12T12:20:12.689244",
     "exception": false,
     "start_time": "2022-06-12T12:20:12.664623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n'XGBoost': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\n          colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\\n          gamma=0, gpu_id=-1, importance_type='gain',\\n          interaction_constraints='', learning_rate=0.300000012,\\n          max_delta_step=0, max_depth=6, min_child_weight=1, #missing=nan,\\n          monotone_constraints='()', n_estimators=100, n_jobs=16,\\n          num_parallel_tree=1,  random_state=0, #objective='multi:softprob',\\n          reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\\n          tree_method='exact', use_label_encoder=False,\\n          validate_parameters=1, verbosity=None)\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allModels = {\n",
    "    \n",
    "    'LightGBM' : LGBMClassifier(\n",
    "            boosting_type = 'goss',  ### Added as per notebook comments ###\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1, ),\n",
    "    \n",
    "   'HGBC' :  HistGradientBoostingClassifier(learning_rate=0.01, \n",
    "        max_iter=2000, max_leaf_nodes=6, validation_fraction=0.2, \n",
    "        n_iter_no_change=15, random_state=42),\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "'XGBoost': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "          colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
    "          gamma=0, gpu_id=-1, importance_type='gain',\n",
    "          interaction_constraints='', learning_rate=0.300000012,\n",
    "          max_delta_step=0, max_depth=6, min_child_weight=1, #missing=nan,\n",
    "          monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
    "          num_parallel_tree=1,  random_state=0, #objective='multi:softprob',\n",
    "          reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
    "          tree_method='exact', use_label_encoder=False,\n",
    "          validate_parameters=1, verbosity=None)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fc6157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:12.714501Z",
     "iopub.status.busy": "2022-06-12T12:20:12.713758Z",
     "iopub.status.idle": "2022-06-12T12:20:12.719817Z",
     "shell.execute_reply": "2022-06-12T12:20:12.718881Z"
    },
    "papermill": {
     "duration": 0.020845,
     "end_time": "2022-06-12T12:20:12.721847",
     "exception": false,
     "start_time": "2022-06-12T12:20:12.701002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conf_matrix(y,pred):\n",
    "    \n",
    "    ((tn, fp), (fn, tp)) = metrics.confusion_matrix(y, pred)\n",
    "    ((tnr,fpr),(fnr,tpr))= metrics.confusion_matrix(y, pred, \n",
    "            normalize='true')\n",
    "    return pd.DataFrame([[f'TN = {tn} (TNR = {tnr:1.2%})', \n",
    "                                f'FP = {fp} (FPR = {fpr:1.2%})'], \n",
    "                             [f'FN = {fn} (FNR = {fnr:1.2%})', \n",
    "                                    f'TP = {tp} (TPR = {tpr:1.2%})']],\n",
    "                index=['True 0(Legit)', 'True 1(Fraud)'], \n",
    "                columns=['Pred 0(Approve as Legit)', \n",
    "                                'Pred 1(Deny as Fraud)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dd9c78e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T12:20:12.749240Z",
     "iopub.status.busy": "2022-06-12T12:20:12.748664Z",
     "iopub.status.idle": "2022-06-12T13:22:08.894205Z",
     "shell.execute_reply": "2022-06-12T13:22:08.893044Z"
    },
    "papermill": {
     "duration": 3716.189555,
     "end_time": "2022-06-12T13:22:08.924845",
     "exception": false,
     "start_time": "2022-06-12T12:20:12.735290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "Bureau df shape: (305811, 116)\n",
      "Process bureau and bureau_balance - done in 28s\n",
      "Previous applications df shape: (338857, 249)\n",
      "Process previous_applications - done in 30s\n",
      "Pos-cash balance df shape: (337252, 18)\n",
      "Process POS-CASH balance - done in 16s\n",
      "Installments payments df shape: (339587, 26)\n",
      "Process installments payments - done in 39s\n",
      "Credit card balance df shape: (103558, 141)\n",
      "Process credit card balance - done in 31s\n",
      "### Picked data ###\n",
      "Run main - done in 3s\n",
      "### Total datapoints         index  SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
      "0           0      100002     1.0            0             0                0   \n",
      "1           1      100003     0.0            1             0                1   \n",
      "2           2      100004     0.0            0             1                0   \n",
      "3           3      100006     0.0            1             0                0   \n",
      "4           4      100007     0.0            0             0                0   \n",
      "...       ...         ...     ...          ...           ...              ...   \n",
      "356250  48739      456221     NaN            1             0                0   \n",
      "356251  48740      456222     NaN            1             0                1   \n",
      "356252  48741      456223     NaN            1             1                0   \n",
      "356253  48742      456224     NaN            0             0                1   \n",
      "356254  48743      456250     NaN            1             1                1   \n",
      "\n",
      "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  ...  \\\n",
      "0                  0          202500.0    406597.5      24700.5  ...   \n",
      "1                  0          270000.0   1293502.5      35698.5  ...   \n",
      "2                  0           67500.0    135000.0       6750.0  ...   \n",
      "3                  0          135000.0    312682.5      29686.5  ...   \n",
      "4                  0          121500.0    513000.0      21865.5  ...   \n",
      "...              ...               ...         ...          ...  ...   \n",
      "356250             0          121500.0    412560.0      17473.5  ...   \n",
      "356251             2          157500.0    622413.0      31909.5  ...   \n",
      "356252             1          202500.0    315000.0      33205.5  ...   \n",
      "356253             0          225000.0    450000.0      25128.0  ...   \n",
      "356254             0          135000.0    312768.0      24709.5  ...   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
      "0                                      NaN   \n",
      "1                                      NaN   \n",
      "2                                      NaN   \n",
      "3                                      0.0   \n",
      "4                                      NaN   \n",
      "...                                    ...   \n",
      "356250                                 NaN   \n",
      "356251                                 NaN   \n",
      "356252                                 NaN   \n",
      "356253                                 NaN   \n",
      "356254                                 0.0   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_Signed_MEAN  \\\n",
      "0                                       NaN   \n",
      "1                                       NaN   \n",
      "2                                       NaN   \n",
      "3                                       0.0   \n",
      "4                                       NaN   \n",
      "...                                     ...   \n",
      "356250                                  NaN   \n",
      "356251                                  NaN   \n",
      "356252                                  NaN   \n",
      "356253                                  NaN   \n",
      "356254                                  0.0   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
      "0                                      NaN   \n",
      "1                                      NaN   \n",
      "2                                      NaN   \n",
      "3                                      0.0   \n",
      "4                                      NaN   \n",
      "...                                    ...   \n",
      "356250                                 NaN   \n",
      "356251                                 NaN   \n",
      "356252                                 NaN   \n",
      "356253                                 NaN   \n",
      "356254                                 0.0   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_Signed_VAR  CC_NAME_CONTRACT_STATUS_nan_MIN  \\\n",
      "0                                      NaN                              NaN   \n",
      "1                                      NaN                              NaN   \n",
      "2                                      NaN                              NaN   \n",
      "3                                      0.0                              0.0   \n",
      "4                                      NaN                              NaN   \n",
      "...                                    ...                              ...   \n",
      "356250                                 NaN                              NaN   \n",
      "356251                                 NaN                              NaN   \n",
      "356252                                 NaN                              NaN   \n",
      "356253                                 NaN                              NaN   \n",
      "356254                                 0.0                              0.0   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_nan_MAX  CC_NAME_CONTRACT_STATUS_nan_MEAN  \\\n",
      "0                                   NaN                               NaN   \n",
      "1                                   NaN                               NaN   \n",
      "2                                   NaN                               NaN   \n",
      "3                                   0.0                               0.0   \n",
      "4                                   NaN                               NaN   \n",
      "...                                 ...                               ...   \n",
      "356250                              NaN                               NaN   \n",
      "356251                              NaN                               NaN   \n",
      "356252                              NaN                               NaN   \n",
      "356253                              NaN                               NaN   \n",
      "356254                              0.0                               0.0   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_nan_SUM  CC_NAME_CONTRACT_STATUS_nan_VAR  \\\n",
      "0                                   NaN                              NaN   \n",
      "1                                   NaN                              NaN   \n",
      "2                                   NaN                              NaN   \n",
      "3                                   0.0                              0.0   \n",
      "4                                   NaN                              NaN   \n",
      "...                                 ...                              ...   \n",
      "356250                              NaN                              NaN   \n",
      "356251                              NaN                              NaN   \n",
      "356252                              NaN                              NaN   \n",
      "356253                              NaN                              NaN   \n",
      "356254                              0.0                              0.0   \n",
      "\n",
      "        CC_COUNT  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            6.0  \n",
      "4            NaN  \n",
      "...          ...  \n",
      "356250       NaN  \n",
      "356251       NaN  \n",
      "356252       NaN  \n",
      "356253       NaN  \n",
      "356254      12.0  \n",
      "\n",
      "[356251 rows x 811 columns] ###\n",
      "### Datapoints excluding test file          index  SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  \\\n",
      "0            0      100002     1.0            0             0   \n",
      "1            1      100003     0.0            1             0   \n",
      "2            2      100004     0.0            0             1   \n",
      "3            3      100006     0.0            1             0   \n",
      "4            4      100007     0.0            0             0   \n",
      "...        ...         ...     ...          ...           ...   \n",
      "307506  307506      456251     0.0            0             0   \n",
      "307507  307507      456252     0.0            1             0   \n",
      "307508  307508      456253     0.0            1             0   \n",
      "307509  307509      456254     1.0            1             0   \n",
      "307510  307510      456255     0.0            1             0   \n",
      "\n",
      "        FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
      "0                     0             0          202500.0    406597.5   \n",
      "1                     1             0          270000.0   1293502.5   \n",
      "2                     0             0           67500.0    135000.0   \n",
      "3                     0             0          135000.0    312682.5   \n",
      "4                     0             0          121500.0    513000.0   \n",
      "...                 ...           ...               ...         ...   \n",
      "307506                1             0          157500.0    254700.0   \n",
      "307507                0             0           72000.0    269550.0   \n",
      "307508                0             0          153000.0    677664.0   \n",
      "307509                0             0          171000.0    370107.0   \n",
      "307510                1             0          157500.0    675000.0   \n",
      "\n",
      "        AMT_ANNUITY  ...  CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
      "0           24700.5  ...                                 NaN   \n",
      "1           35698.5  ...                                 NaN   \n",
      "2            6750.0  ...                                 NaN   \n",
      "3           29686.5  ...                                 0.0   \n",
      "4           21865.5  ...                                 NaN   \n",
      "...             ...  ...                                 ...   \n",
      "307506      27558.0  ...                                 NaN   \n",
      "307507      12001.5  ...                                 NaN   \n",
      "307508      29979.0  ...                                 NaN   \n",
      "307509      20205.0  ...                                 NaN   \n",
      "307510      49117.5  ...                                 NaN   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_Signed_MEAN  \\\n",
      "0                                       NaN   \n",
      "1                                       NaN   \n",
      "2                                       NaN   \n",
      "3                                       0.0   \n",
      "4                                       NaN   \n",
      "...                                     ...   \n",
      "307506                                  NaN   \n",
      "307507                                  NaN   \n",
      "307508                                  NaN   \n",
      "307509                                  NaN   \n",
      "307510                                  NaN   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
      "0                                      NaN   \n",
      "1                                      NaN   \n",
      "2                                      NaN   \n",
      "3                                      0.0   \n",
      "4                                      NaN   \n",
      "...                                    ...   \n",
      "307506                                 NaN   \n",
      "307507                                 NaN   \n",
      "307508                                 NaN   \n",
      "307509                                 NaN   \n",
      "307510                                 NaN   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_Signed_VAR  CC_NAME_CONTRACT_STATUS_nan_MIN  \\\n",
      "0                                      NaN                              NaN   \n",
      "1                                      NaN                              NaN   \n",
      "2                                      NaN                              NaN   \n",
      "3                                      0.0                              0.0   \n",
      "4                                      NaN                              NaN   \n",
      "...                                    ...                              ...   \n",
      "307506                                 NaN                              NaN   \n",
      "307507                                 NaN                              NaN   \n",
      "307508                                 NaN                              NaN   \n",
      "307509                                 NaN                              NaN   \n",
      "307510                                 NaN                              NaN   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_nan_MAX  CC_NAME_CONTRACT_STATUS_nan_MEAN  \\\n",
      "0                                   NaN                               NaN   \n",
      "1                                   NaN                               NaN   \n",
      "2                                   NaN                               NaN   \n",
      "3                                   0.0                               0.0   \n",
      "4                                   NaN                               NaN   \n",
      "...                                 ...                               ...   \n",
      "307506                              NaN                               NaN   \n",
      "307507                              NaN                               NaN   \n",
      "307508                              NaN                               NaN   \n",
      "307509                              NaN                               NaN   \n",
      "307510                              NaN                               NaN   \n",
      "\n",
      "        CC_NAME_CONTRACT_STATUS_nan_SUM  CC_NAME_CONTRACT_STATUS_nan_VAR  \\\n",
      "0                                   NaN                              NaN   \n",
      "1                                   NaN                              NaN   \n",
      "2                                   NaN                              NaN   \n",
      "3                                   0.0                              0.0   \n",
      "4                                   NaN                              NaN   \n",
      "...                                 ...                              ...   \n",
      "307506                              NaN                              NaN   \n",
      "307507                              NaN                              NaN   \n",
      "307508                              NaN                              NaN   \n",
      "307509                              NaN                              NaN   \n",
      "307510                              NaN                              NaN   \n",
      "\n",
      "        CC_COUNT  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            6.0  \n",
      "4            NaN  \n",
      "...          ...  \n",
      "307506       NaN  \n",
      "307507       NaN  \n",
      "307508       NaN  \n",
      "307509       NaN  \n",
      "307510       NaN  \n",
      "\n",
      "[307507 rows x 811 columns] ###\n",
      "Starting LightGBM.... Train shape: (215254, 808), test shape: (92253, 808)\n",
      "[LightGBM] [Warning] num_threads is set with nthread=4, will be overridden by n_jobs=-1. Current value: num_threads=-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## Stats for LightGBM ##########################\n",
      "                Pred 0(Approve as Legit)   Pred 1(Deny as Fraud)\n",
      "True 0(Legit)  TN = 84325 (TNR = 99.43%)  FP = 486 (FPR = 0.57%)\n",
      "True 1(Fraud)   FN = 6967 (FNR = 93.62%)  TP = 475 (TPR = 6.38%)\n",
      "Recall: 0.064\n",
      "############################################\n",
      "Starting HGBC.... Train shape: (215254, 808), test shape: (92253, 808)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## Stats for HGBC ##########################\n",
      "                Pred 0(Approve as Legit)   Pred 1(Deny as Fraud)\n",
      "True 0(Legit)  TN = 84676 (TNR = 99.84%)  FP = 135 (FPR = 0.16%)\n",
      "True 1(Fraud)   FN = 7248 (FNR = 97.39%)  TP = 194 (TPR = 2.61%)\n",
      "Recall: 0.026\n",
      "############################################\n",
      "Full model run - done in 3716s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def runAlgos(algoName, X_train, X_test, y_train, y_test):\n",
    "   \n",
    "    print(\"Starting {}.... Train shape: {}, test shape: {}\".format(algoName, X_train.shape, X_test.shape))\n",
    "\n",
    "    clf = allModels.get(algoName)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(\"################## Stats for {} ##########################\".format(algoName))\n",
    "\n",
    "    print(conf_matrix(y_test,y_pred))\n",
    "    # calculate recall\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    print('Recall: %.3f' % recall)\n",
    "    print(\"############################################\")\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "def prepare(debug = False):\n",
    "    num_rows = 10000 if debug else None\n",
    "    df = application_train_test(num_rows)\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        gc.collect()\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        gc.collect()\n",
    "    with timer(\"Run main\"):\n",
    "        \n",
    "        \n",
    "        df.to_pickle(file_name)\n",
    "        #df = df.dropna()\n",
    "        print(\"### Picked data ###\")\n",
    "        #df = pd.read_pickle(file_name)\n",
    "        #df = df[:1000]\n",
    "        return df\n",
    "    \n",
    "def main():\n",
    "    df = prepare(debug = False) #pd.read_pickle(file_name) #prepare(debug = False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = getDatasets(df)\n",
    "    # try - https://machinelearningmastery.com/voting-ensembles-with-python/\n",
    "    for k in allModels.keys():\n",
    "\n",
    "        runAlgos(k, X_train, X_test, y_train, y_test)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#submission_file_name = \"submission_kernel02.csv\"\n",
    "with timer(\"Full model run\"):\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce371b3",
   "metadata": {
    "papermill": {
     "duration": 0.018678,
     "end_time": "2022-06-12T13:22:08.961859",
     "exception": false,
     "start_time": "2022-06-12T13:22:08.943181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3729.262112,
   "end_time": "2022-06-12T13:22:10.115601",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-12T12:20:00.853489",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b17b25d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:10.191692Z",
     "iopub.status.busy": "2022-06-12T14:21:10.191055Z",
     "iopub.status.idle": "2022-06-12T14:21:10.203854Z",
     "shell.execute_reply": "2022-06-12T14:21:10.202958Z"
    },
    "papermill": {
     "duration": 0.025739,
     "end_time": "2022-06-12T14:21:10.209573",
     "exception": false,
     "start_time": "2022-06-12T14:21:10.183834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/home-credit-default-risk/sample_submission.csv\n",
      "/kaggle/input/home-credit-default-risk/bureau_balance.csv\n",
      "/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv\n",
      "/kaggle/input/home-credit-default-risk/application_train.csv\n",
      "/kaggle/input/home-credit-default-risk/HomeCredit_columns_description.csv\n",
      "/kaggle/input/home-credit-default-risk/application_test.csv\n",
      "/kaggle/input/home-credit-default-risk/previous_application.csv\n",
      "/kaggle/input/home-credit-default-risk/credit_card_balance.csv\n",
      "/kaggle/input/home-credit-default-risk/installments_payments.csv\n",
      "/kaggle/input/home-credit-default-risk/bureau.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36ffb4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:10.222147Z",
     "iopub.status.busy": "2022-06-12T14:21:10.221744Z",
     "iopub.status.idle": "2022-06-12T14:21:12.509177Z",
     "shell.execute_reply": "2022-06-12T14:21:12.508321Z"
    },
    "papermill": {
     "duration": 2.295698,
     "end_time": "2022-06-12T14:21:12.511521",
     "exception": false,
     "start_time": "2022-06-12T14:21:10.215823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "file_name = '/kaggle/working/data.pickl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff20313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:12.522619Z",
     "iopub.status.busy": "2022-06-12T14:21:12.522213Z",
     "iopub.status.idle": "2022-06-12T14:21:12.529331Z",
     "shell.execute_reply": "2022-06-12T14:21:12.528448Z"
    },
    "papermill": {
     "duration": 0.015017,
     "end_time": "2022-06-12T14:21:12.531386",
     "exception": false,
     "start_time": "2022-06-12T14:21:12.516369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06128d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:12.542597Z",
     "iopub.status.busy": "2022-06-12T14:21:12.542224Z",
     "iopub.status.idle": "2022-06-12T14:21:12.566391Z",
     "shell.execute_reply": "2022-06-12T14:21:12.565346Z"
    },
    "papermill": {
     "duration": 0.032391,
     "end_time": "2022-06-12T14:21:12.568544",
     "exception": false,
     "start_time": "2022-06-12T14:21:12.536153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = True):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau_balance.csv', nrows = num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bacb8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:12.579622Z",
     "iopub.status.busy": "2022-06-12T14:21:12.579238Z",
     "iopub.status.idle": "2022-06-12T14:21:12.612887Z",
     "shell.execute_reply": "2022-06-12T14:21:12.611927Z"
    },
    "papermill": {
     "duration": 0.041671,
     "end_time": "2022-06-12T14:21:12.614976",
     "exception": false,
     "start_time": "2022-06-12T14:21:12.573305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('/kaggle/input/home-credit-default-risk/previous_application.csv', nrows = num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n",
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = pd.read_csv('/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv', nrows = num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg\n",
    "    \n",
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('/kaggle/input/home-credit-default-risk/installments_payments.csv', nrows = num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = pd.read_csv('/kaggle/input/home-credit-default-risk/credit_card_balance.csv', nrows = num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4898268",
   "metadata": {
    "papermill": {
     "duration": 0.004571,
     "end_time": "2022-06-12T14:21:12.624365",
     "exception": false,
     "start_time": "2022-06-12T14:21:12.619794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb\n",
    "https://stackoverflow.com/questions/70841834/false-positive-vs-false-negative-trade-off-plot\n",
    "https://towardsdatascience.com/how-to-deal-with-imbalanced-classification-without-re-balancing-the-data-8a3c02353fe3\n",
    "https://towardsdatascience.com/classifying-model-outcomes-true-false-positives-negatives-177c1e702810\n",
    "https://www.analyticsvidhya.com/blog/2020/11/a-tour-of-evaluation-metrics-for-machine-learning/\n",
    "https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c34e44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:12.635012Z",
     "iopub.status.busy": "2022-06-12T14:21:12.634643Z",
     "iopub.status.idle": "2022-06-12T14:21:12.958929Z",
     "shell.execute_reply": "2022-06-12T14:21:12.958050Z"
    },
    "papermill": {
     "duration": 0.332845,
     "end_time": "2022-06-12T14:21:12.961749",
     "exception": false,
     "start_time": "2022-06-12T14:21:12.628904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  \"Since version 1.0, \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import model_selection, metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad49d4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:12.972733Z",
     "iopub.status.busy": "2022-06-12T14:21:12.972383Z",
     "iopub.status.idle": "2022-06-12T14:21:12.980858Z",
     "shell.execute_reply": "2022-06-12T14:21:12.980066Z"
    },
    "papermill": {
     "duration": 0.016494,
     "end_time": "2022-06-12T14:21:12.983133",
     "exception": false,
     "start_time": "2022-06-12T14:21:12.966639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def getDatasets(df):\n",
    "    print(\"### Total datapoints {} ###\".format(df))\n",
    "    df = df[df['TARGET'].notnull()]\n",
    "    print(\"### Datapoints excluding test file {} ###\".format(df))\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    feature_col_names = [f for f in df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    predicted_class_names = ['TARGET']\n",
    "    \n",
    "    X = df[feature_col_names].values\n",
    "\n",
    "    Y = df[predicted_class_names].values\n",
    "\n",
    "    split_test_size = 0.3\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=split_test_size, random_state = 42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f8e4038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:12.994610Z",
     "iopub.status.busy": "2022-06-12T14:21:12.994215Z",
     "iopub.status.idle": "2022-06-12T14:21:13.006175Z",
     "shell.execute_reply": "2022-06-12T14:21:13.004960Z"
    },
    "papermill": {
     "duration": 0.019993,
     "end_time": "2022-06-12T14:21:13.008215",
     "exception": false,
     "start_time": "2022-06-12T14:21:12.988222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n'XGBoost': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\n          colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\\n          gamma=0, gpu_id=-1, importance_type='gain',\\n          interaction_constraints='', learning_rate=0.300000012,\\n          max_delta_step=0, max_depth=6, min_child_weight=1, #missing=nan,\\n          monotone_constraints='()', n_estimators=100, n_jobs=16,\\n          num_parallel_tree=1,  random_state=0, #objective='multi:softprob',\\n          reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\\n          tree_method='exact', use_label_encoder=False,\\n          validate_parameters=1, verbosity=None)\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allModels = {\n",
    "    \n",
    "    'LightGBM' : LGBMClassifier(\n",
    "            boosting_type = 'goss',  ### Added as per notebook comments ###\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1, ),\n",
    "    \n",
    "   'HGBC' :  HistGradientBoostingClassifier(learning_rate=0.01, \n",
    "        max_iter=2000, max_leaf_nodes=6, validation_fraction=0.2, \n",
    "        n_iter_no_change=15, random_state=42),\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "'XGBoost': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "          colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
    "          gamma=0, gpu_id=-1, importance_type='gain',\n",
    "          interaction_constraints='', learning_rate=0.300000012,\n",
    "          max_delta_step=0, max_depth=6, min_child_weight=1, #missing=nan,\n",
    "          monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
    "          num_parallel_tree=1,  random_state=0, #objective='multi:softprob',\n",
    "          reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
    "          tree_method='exact', use_label_encoder=False,\n",
    "          validate_parameters=1, verbosity=None)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4320737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:13.020407Z",
     "iopub.status.busy": "2022-06-12T14:21:13.019997Z",
     "iopub.status.idle": "2022-06-12T14:21:13.026696Z",
     "shell.execute_reply": "2022-06-12T14:21:13.025924Z"
    },
    "papermill": {
     "duration": 0.014839,
     "end_time": "2022-06-12T14:21:13.028517",
     "exception": false,
     "start_time": "2022-06-12T14:21:13.013678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conf_matrix(y,pred):\n",
    "    \n",
    "    ((tn, fp), (fn, tp)) = metrics.confusion_matrix(y, pred)\n",
    "    ((tnr,fpr),(fnr,tpr))= metrics.confusion_matrix(y, pred, \n",
    "            normalize='true')\n",
    "    return pd.DataFrame([[f'TN = {tn} (TNR = {tnr:1.2%})', \n",
    "                                f'FP = {fp} (FPR = {fpr:1.2%})'], \n",
    "                             [f'FN = {fn} (FNR = {fnr:1.2%})', \n",
    "                                    f'TP = {tp} (TPR = {tpr:1.2%})']],\n",
    "                index=['True 0(Legit)', 'True 1(Fraud)'], \n",
    "                columns=['Pred 0(Approve as Legit)', \n",
    "                                'Pred 1(Deny as Fraud)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f236ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T14:21:13.040420Z",
     "iopub.status.busy": "2022-06-12T14:21:13.039995Z",
     "iopub.status.idle": "2022-06-12T14:21:27.781347Z",
     "shell.execute_reply": "2022-06-12T14:21:27.780015Z"
    },
    "papermill": {
     "duration": 14.750091,
     "end_time": "2022-06-12T14:21:27.783711",
     "exception": false,
     "start_time": "2022-06-12T14:21:13.033620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "### Picked data ###\n",
      "Run main - done in 0s\n",
      "### Total datapoints          index  SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  \\\n",
      "71          71      100083     0.0            0             1   \n",
      "124        124      100145     0.0            1             1   \n",
      "152        152      100179     0.0            1             1   \n",
      "161        161      100190     0.0            0             1   \n",
      "164        164      100193     0.0            1             1   \n",
      "...        ...         ...     ...          ...           ...   \n",
      "307358  307358      456083     0.0            1             1   \n",
      "307359  307359      456084     0.0            1             1   \n",
      "307407  307407      456140     1.0            1             1   \n",
      "307456  307456      456195     0.0            1             1   \n",
      "307482  307482      456226     0.0            1             1   \n",
      "\n",
      "        FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
      "71                    0             0          103500.0    573628.5   \n",
      "124                   0             1          202500.0    260725.5   \n",
      "152                   1             0          202500.0    675000.0   \n",
      "161                   1             0          162000.0    263686.5   \n",
      "164                   1             0          225000.0    296280.0   \n",
      "...                 ...           ...               ...         ...   \n",
      "307358                0             2          112500.0    361462.5   \n",
      "307359                0             1           99000.0    675000.0   \n",
      "307407                0             1          261000.0    711454.5   \n",
      "307456                0             0           94500.0    270000.0   \n",
      "307482                0             0          225000.0    500566.5   \n",
      "\n",
      "        AMT_ANNUITY  ...  WALLSMATERIAL_MODE_Wooden  WALLSMATERIAL_MODE_nan  \\\n",
      "71          24435.0  ...                          0                       0   \n",
      "124         16789.5  ...                          0                       0   \n",
      "152         53329.5  ...                          0                       0   \n",
      "161         24781.5  ...                          0                       0   \n",
      "164         15124.5  ...                          0                       0   \n",
      "...             ...  ...                        ...                     ...   \n",
      "307358      16051.5  ...                          0                       0   \n",
      "307359      21906.0  ...                          0                       0   \n",
      "307407      47673.0  ...                          0                       0   \n",
      "307456      15075.0  ...                          0                       0   \n",
      "307482      34969.5  ...                          0                       0   \n",
      "\n",
      "        EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \\\n",
      "71                           1                        0   \n",
      "124                          1                        0   \n",
      "152                          1                        0   \n",
      "161                          1                        0   \n",
      "164                          1                        0   \n",
      "...                        ...                      ...   \n",
      "307358                       1                        0   \n",
      "307359                       1                        0   \n",
      "307407                       1                        0   \n",
      "307456                       1                        0   \n",
      "307482                       1                        0   \n",
      "\n",
      "        EMERGENCYSTATE_MODE_nan  DAYS_EMPLOYED_PERC  INCOME_CREDIT_PERC  \\\n",
      "71                            0            0.057900            0.180430   \n",
      "124                           0            0.268702            0.776679   \n",
      "152                           0            0.203165            0.300000   \n",
      "161                           0            0.320069            0.614366   \n",
      "164                           0            0.052576            0.759417   \n",
      "...                         ...                 ...                 ...   \n",
      "307358                        0            0.073637            0.311236   \n",
      "307359                        0            0.144285            0.146667   \n",
      "307407                        0            0.143859            0.366854   \n",
      "307456                        0            0.269288            0.350000   \n",
      "307482                        0            0.016022            0.449491   \n",
      "\n",
      "        INCOME_PER_PERSON  ANNUITY_INCOME_PERC  PAYMENT_RATE  \n",
      "71                51750.0             0.236087      0.042597  \n",
      "124              101250.0             0.082911      0.064395  \n",
      "152              101250.0             0.263356      0.079007  \n",
      "161               81000.0             0.152972      0.093981  \n",
      "164              225000.0             0.067220      0.051048  \n",
      "...                   ...                  ...           ...  \n",
      "307358            28125.0             0.142680      0.044407  \n",
      "307359            49500.0             0.221273      0.032453  \n",
      "307407            87000.0             0.182655      0.067008  \n",
      "307456            47250.0             0.159524      0.055833  \n",
      "307482           112500.0             0.155420      0.069860  \n",
      "\n",
      "[10745 rows x 261 columns] ###\n",
      "### Datapoints excluding test file          index  SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  \\\n",
      "71          71      100083     0.0            0             1   \n",
      "124        124      100145     0.0            1             1   \n",
      "152        152      100179     0.0            1             1   \n",
      "161        161      100190     0.0            0             1   \n",
      "164        164      100193     0.0            1             1   \n",
      "...        ...         ...     ...          ...           ...   \n",
      "307358  307358      456083     0.0            1             1   \n",
      "307359  307359      456084     0.0            1             1   \n",
      "307407  307407      456140     1.0            1             1   \n",
      "307456  307456      456195     0.0            1             1   \n",
      "307482  307482      456226     0.0            1             1   \n",
      "\n",
      "        FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
      "71                    0             0          103500.0    573628.5   \n",
      "124                   0             1          202500.0    260725.5   \n",
      "152                   1             0          202500.0    675000.0   \n",
      "161                   1             0          162000.0    263686.5   \n",
      "164                   1             0          225000.0    296280.0   \n",
      "...                 ...           ...               ...         ...   \n",
      "307358                0             2          112500.0    361462.5   \n",
      "307359                0             1           99000.0    675000.0   \n",
      "307407                0             1          261000.0    711454.5   \n",
      "307456                0             0           94500.0    270000.0   \n",
      "307482                0             0          225000.0    500566.5   \n",
      "\n",
      "        AMT_ANNUITY  ...  WALLSMATERIAL_MODE_Wooden  WALLSMATERIAL_MODE_nan  \\\n",
      "71          24435.0  ...                          0                       0   \n",
      "124         16789.5  ...                          0                       0   \n",
      "152         53329.5  ...                          0                       0   \n",
      "161         24781.5  ...                          0                       0   \n",
      "164         15124.5  ...                          0                       0   \n",
      "...             ...  ...                        ...                     ...   \n",
      "307358      16051.5  ...                          0                       0   \n",
      "307359      21906.0  ...                          0                       0   \n",
      "307407      47673.0  ...                          0                       0   \n",
      "307456      15075.0  ...                          0                       0   \n",
      "307482      34969.5  ...                          0                       0   \n",
      "\n",
      "        EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \\\n",
      "71                           1                        0   \n",
      "124                          1                        0   \n",
      "152                          1                        0   \n",
      "161                          1                        0   \n",
      "164                          1                        0   \n",
      "...                        ...                      ...   \n",
      "307358                       1                        0   \n",
      "307359                       1                        0   \n",
      "307407                       1                        0   \n",
      "307456                       1                        0   \n",
      "307482                       1                        0   \n",
      "\n",
      "        EMERGENCYSTATE_MODE_nan  DAYS_EMPLOYED_PERC  INCOME_CREDIT_PERC  \\\n",
      "71                            0            0.057900            0.180430   \n",
      "124                           0            0.268702            0.776679   \n",
      "152                           0            0.203165            0.300000   \n",
      "161                           0            0.320069            0.614366   \n",
      "164                           0            0.052576            0.759417   \n",
      "...                         ...                 ...                 ...   \n",
      "307358                        0            0.073637            0.311236   \n",
      "307359                        0            0.144285            0.146667   \n",
      "307407                        0            0.143859            0.366854   \n",
      "307456                        0            0.269288            0.350000   \n",
      "307482                        0            0.016022            0.449491   \n",
      "\n",
      "        INCOME_PER_PERSON  ANNUITY_INCOME_PERC  PAYMENT_RATE  \n",
      "71                51750.0             0.236087      0.042597  \n",
      "124              101250.0             0.082911      0.064395  \n",
      "152              101250.0             0.263356      0.079007  \n",
      "161               81000.0             0.152972      0.093981  \n",
      "164              225000.0             0.067220      0.051048  \n",
      "...                   ...                  ...           ...  \n",
      "307358            28125.0             0.142680      0.044407  \n",
      "307359            49500.0             0.221273      0.032453  \n",
      "307407            87000.0             0.182655      0.067008  \n",
      "307456            47250.0             0.159524      0.055833  \n",
      "307482           112500.0             0.155420      0.069860  \n",
      "\n",
      "[10745 rows x 261 columns] ###\n",
      "459 7062 6.499575191163977\n",
      "7521\n",
      "3224\n",
      "7521\n",
      "3224\n",
      "{0, 1}\n",
      "               Pred 0(Approve as Legit)   Pred 1(Deny as Fraud)\n",
      "True 0(Legit)  TN = 2806 (TNR = 92.73%)  FP = 220 (FPR = 7.27%)\n",
      "True 1(Fraud)   FN = 186 (FNR = 93.94%)   TP = 12 (TPR = 6.06%)\n",
      "Recall: 0.061\n",
      "ROC AUC: 0.4940\n",
      "############################################\n",
      "Full model run - done in 15s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def runAlgos(algoName, X_train, X_test, y_train, y_test):\n",
    "   \n",
    "    print(\"Starting {}.... Train shape: {}, test shape: {}\".format(algoName, X_train.shape, X_test.shape))\n",
    "\n",
    "    clf = allModels.get(algoName)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(\"################## Stats for {} ##########################\".format(algoName))\n",
    "\n",
    "    #print(conf_matrix(y_test,y_pred))\n",
    "    # calculate recall\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    print('Recall: %.3f' % recall)\n",
    "    print(\"############################################\")\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "def run2(X_train, X_test, y_train, y_test, outlier_fraction):\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    isof = IsolationForest(max_samples=len(X_train),contamination=outlier_fraction)\n",
    "    isof.fit(X_train)\n",
    "    scores_pred = isof.decision_function(X_train)\n",
    "    y_pred = isof.predict(X_test)\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    print(set(y_pred))\n",
    "    print(conf_matrix(y_test,y_pred))\n",
    "    # calculate recall\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    print('Recall: %.3f' % recall)\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    score = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"ROC AUC: {score:.4f}\")\n",
    "    #plot_roc_curve(isof, X_test, y_test, name = 'IsolationForest')\n",
    "    print(\"############################################\")\n",
    "\n",
    "\n",
    "def prepare(debug = False):\n",
    "    num_rows = 10000 if debug else None\n",
    "    df = application_train_test(num_rows)\n",
    "    \"\"\"\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        gc.collect()\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        gc.collect()\n",
    "    \"\"\"\n",
    "    with timer(\"Run main\"):\n",
    "        \n",
    "        \n",
    "        #df.to_pickle(file_name)\n",
    "        #df = df.dropna()\n",
    "        print(\"### Picked data ###\")\n",
    "        #df = pd.read_pickle(file_name)\n",
    "        #df = df[:1000]\n",
    "        return df\n",
    "    \n",
    "def main():\n",
    "    df =prepare(debug = False) # pd.read_pickle(file_name) #\n",
    "    df = df.dropna()\n",
    "    X_train, X_test, y_train, y_test = getDatasets(df)\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    from sklearn.neighbors import LocalOutlierFactor\n",
    "    import numpy as np\n",
    "\n",
    "    fraud = y_train[np.where(y_train == 1)].size\n",
    "    valid = y_train[np.where(y_train == 0)].size\n",
    "    outlier_fraction = fraud/float(valid)\n",
    "    print(fraud, valid, outlier_fraction*100)\n",
    "    for t in (X_train, X_test, y_train, y_test):\n",
    "        print(len(t))\n",
    "    run2(X_train, X_test, y_train, y_test, outlier_fraction)\n",
    "    # try - https://machinelearningmastery.com/voting-ensembles-with-python/\n",
    "    \"\"\"\n",
    "    for k in allModels.keys():\n",
    "\n",
    "        runAlgos(k, X_train, X_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#submission_file_name = \"submission_kernel02.csv\"\n",
    "with timer(\"Full model run\"):\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad3b92",
   "metadata": {
    "papermill": {
     "duration": 0.005282,
     "end_time": "2022-06-12T14:21:27.794869",
     "exception": false,
     "start_time": "2022-06-12T14:21:27.789587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.31993,
   "end_time": "2022-06-12T14:21:28.622367",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-12T14:21:00.302437",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
